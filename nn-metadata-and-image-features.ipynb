{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9173004,"sourceType":"datasetVersion","datasetId":5543514},{"sourceId":9234672,"sourceType":"datasetVersion","datasetId":5585731},{"sourceId":9260035,"sourceType":"datasetVersion","datasetId":5602950},{"sourceId":9260577,"sourceType":"datasetVersion","datasetId":5603341},{"sourceId":9266839,"sourceType":"datasetVersion","datasetId":5607889},{"sourceId":9335620,"sourceType":"datasetVersion","datasetId":5657077},{"sourceId":3729,"sourceType":"modelInstanceVersion","modelInstanceId":2656,"modelId":312}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":793.680734,"end_time":"2024-06-29T23:30:34.642937","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-29T23:17:20.962203","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"14f33eda98294bf7ab2c201ef8c071b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efc119d2e1e0456fa0a6593c16a85dc2","placeholder":"​","style":"IPY_MODEL_f4be4b7893f14d71a8658ad521e9d4e9","value":" 21.4M/21.4M [00:00&lt;00:00, 41.1MB/s]"}},"18bdb1a4a13e4aee9cc51601b980aca0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"244eb860d230481c85c8db4fd77fb99a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47503710d50a4aaba66bd273e31797b0","IPY_MODEL_938dc29705ca4174ab708b0e84ac456c","IPY_MODEL_14f33eda98294bf7ab2c201ef8c071b0"],"layout":"IPY_MODEL_18bdb1a4a13e4aee9cc51601b980aca0"}},"256368e0b8da40ffaab43806b6e7bdfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47503710d50a4aaba66bd273e31797b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1c7099741224d6d95e8f291dac107aa","placeholder":"​","style":"IPY_MODEL_e70b5a1f96bf4ddf9ac9271b3aa6ad1a","value":"model.safetensors: 100%"}},"938dc29705ca4174ab708b0e84ac456c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c198e83f65a043f6b6886c6984bf6303","max":21355344,"min":0,"orientation":"horizontal","style":"IPY_MODEL_256368e0b8da40ffaab43806b6e7bdfc","value":21355344}},"a1c7099741224d6d95e8f291dac107aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c198e83f65a043f6b6886c6984bf6303":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e70b5a1f96bf4ddf9ac9271b3aa6ad1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efc119d2e1e0456fa0a6593c16a85dc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4be4b7893f14d71a8658ad521e9d4e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torcheval","metadata":{"papermill":{"duration":13.648463,"end_time":"2024-06-29T23:17:37.368242","exception":false,"start_time":"2024-06-29T23:17:23.719779","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\nimport pickle\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\nfrom torcheval.metrics.functional import binary_auroc\n\n# Utils\nimport joblib\nfrom tqdm.auto import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold, KFold\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"papermill":{"duration":9.086974,"end_time":"2024-06-29T23:17:46.466572","exception":false,"start_time":"2024-06-29T23:17:37.379598","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nimport optuna\nimport catboost as cb\nimport lightgbm as lgb\nimport xgboost as xgb","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 42,\n    \"neg_sample_ratio\" : 0.04,\n    \"epochs\": 50,\n    \"img_size\": 384,\n    \"model_name\": \"efficientnet_b3\",\n    #\"checkpoint_path\" : \"/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth\",\n    \"train_batch_size\": 16,\n    \"valid_batch_size\": 32,\n    \"learning_rate\": 1e-4,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 250,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    #'device' : 'cpu'\n}","metadata":{"papermill":{"duration":0.07116,"end_time":"2024-06-29T23:17:46.571192","exception":false,"start_time":"2024-06-29T23:17:46.500032","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"papermill":{"duration":0.021715,"end_time":"2024-06-29T23:17:46.625274","exception":false,"start_time":"2024-06-29T23:17:46.603559","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\nTRAIN_DIR = f'{ROOT_DIR}/train-image/image'","metadata":{"papermill":{"duration":0.017083,"end_time":"2024-06-29T23:17:46.653209","exception":false,"start_time":"2024-06-29T23:17:46.636126","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    return f\"{TRAIN_DIR}/{image_id}.jpg\"","metadata":{"papermill":{"duration":0.017155,"end_time":"2024-06-29T23:17:46.681165","exception":false,"start_time":"2024-06-29T23:17:46.66401","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.jpg\"))","metadata":{"papermill":{"duration":4.053439,"end_time":"2024-06-29T23:17:50.766866","exception":false,"start_time":"2024-06-29T23:17:46.713427","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test=pd.read_csv('/kaggle/input/isic-2024-challenge/test-metadata.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/train-metadata.csv\")\nfor col in df.columns:\n    if((df[col].dtype=='float64' or df[col].dtype=='int64') and df[col].isna().sum()!=0):\n        df[col].fillna(value=df[col].median(),inplace=True);\n    if(df[col].dtype=='object' and df[col].isna().sum()!=0):\n        df[col].fillna(value=df[col].mode()[0],inplace=True);","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(df['patient_id']).shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.under_sampling import RandomUnderSampler\nsampler = RandomUnderSampler(sampling_strategy = 0.004, random_state = CONFIG['seed'])\nX, y = df.drop('target', axis =1), df['target']\nX, y = sampler.fit_resample(X, y)\nX = X.reset_index(drop=True)\ny = y.reset_index(drop=True)\ndf = X\ndf['target'] = y\ndf.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l1 = list(df[df['target']==1]['patient_id'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l2 = list(df[df['target']==0]['patient_id'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"        df.shape, # of positive cases, # of patients\")\nprint(\"original>\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n\ndf_positive = df[df[\"target\"] == 1].reset_index(drop=True)\ndf_negative = df[df[\"target\"] == 0].reset_index(drop=True)\n# df_negative = df_negative[~df_negative.isin(c_l2).any(axis=1)]\n\n# df = pd.concat([df_positive, df_negative.iloc[:10000, :]])  # positive:negative = 1:20\nprint(\"filtered>\", df.shape, df.target.sum(), df[\"patient_id\"].unique().shape)\n\ndf['file_path'] = df['isic_id'].apply(get_train_file_path)\ndf = df[ df[\"file_path\"].isin(train_images) ].reset_index(drop=True)\ndf","metadata":{"papermill":{"duration":7.631613,"end_time":"2024-06-29T23:17:58.409773","exception":false,"start_time":"2024-06-29T23:17:50.77816","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape[0], df.target.sum()","metadata":{"papermill":{"duration":0.020088,"end_time":"2024-06-29T23:17:58.441777","exception":false,"start_time":"2024-06-29T23:17:58.421689","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CONFIG['T_max'] = df.shape[0] * (CONFIG[\"n_fold\"]-1) * CONFIG['epochs'] // CONFIG['train_batch_size'] // CONFIG[\"n_fold\"]\nCONFIG['T_max']","metadata":{"papermill":{"duration":0.020234,"end_time":"2024-06-29T23:17:58.473737","exception":false,"start_time":"2024-06-29T23:17:58.453503","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[df['target']==1]['patient_id'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sgkf = StratifiedGroupKFold(n_splits=CONFIG['n_fold'])\n\nfor fold, ( _, val_) in enumerate(sgkf.split(df, df.target,df.patient_id)):\n      df.loc[val_ , \"kfold\"] = int(fold)","metadata":{"papermill":{"duration":0.466594,"end_time":"2024-06-29T23:17:58.975943","exception":false,"start_time":"2024-06-29T23:17:58.509349","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['kfold'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ISICDataset_for_Train(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df_positive = df[df[\"target\"] == 1].reset_index()\n        self.df_negative = df[df[\"target\"] == 0].reset_index()\n        self.file_names_positive = self.df_positive['file_path'].values\n        self.file_names_negative = self.df_negative['file_path'].values\n        self.targets_positive = self.df_positive['target'].values\n        self.targets_negative = self.df_negative['target'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df_positive) * 2\n    \n    def __getitem__(self, index):\n        if random.random() >= 0.5:\n            df = self.df_positive\n            file_names = self.file_names_positive\n            targets = self.targets_positive\n        else:\n            df = self.df_negative\n            file_names = self.file_names_negative\n            targets = self.targets_negative\n        index = index % df.shape[0]\n        \n        img_path = file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        target = targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'target': target\n        }\n    \nclass ISICDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.targets = df['target'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        target = self.targets[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'target': target\n        }","metadata":{"papermill":{"duration":0.027666,"end_time":"2024-06-29T23:17:59.039604","exception":false,"start_time":"2024-06-29T23:17:59.011938","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMAGE_INPUT_SHAPE = 384","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_transforms = {\n    \"train\": A.Compose([\n            A.Transpose(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.RandomBrightnessContrast(brightness_limit=0.2,contrast_limit=0.2, p=0.75),\n            A.OneOf([\n                A.MotionBlur(blur_limit=5),\n                A.MedianBlur(blur_limit=5),\n                A.GaussianBlur(blur_limit=5),\n                A.GaussNoise(var_limit=(5.0, 30.0)),\n            ], p=0.7),\n\n            A.OneOf([\n                A.OpticalDistortion(distort_limit=1.0),\n                A.GridDistortion(num_steps=5, distort_limit=1.),\n                A.ElasticTransform(alpha=3),\n            ], p=0.7),\n\n            A.CLAHE(clip_limit=4.0, p=0.7),\n            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n            A.Resize(IMAGE_INPUT_SHAPE, IMAGE_INPUT_SHAPE),\n            # A.Cut(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7),\n            A.Normalize(),\n            ToTensorV2(),\n        ]),\n\n    \n    \"valid\":  A.Compose([\n            A.Resize(IMAGE_INPUT_SHAPE, IMAGE_INPUT_SHAPE),\n            A.Normalize(),\n            ToTensorV2(),\n])\n}","metadata":{"papermill":{"duration":0.023138,"end_time":"2024-06-29T23:17:59.09779","exception":false,"start_time":"2024-06-29T23:17:59.074652","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        return self.__class__.__name__ + \\\n                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n                ', ' + 'eps=' + str(self.eps) + ')'","metadata":{"papermill":{"duration":0.02223,"end_time":"2024-06-29T23:17:59.155728","exception":false,"start_time":"2024-06-29T23:17:59.133498","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ISICModel(nn.Module):\n    def __init__(self, model_name, num_classes=1, pretrained=True, checkpoint_path=None):\n        super(ISICModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n\n        in_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.model.global_pool = nn.Identity()\n        self.pooling = GeM()\n        self.linear = nn.Linear(in_features, num_classes)\n\n    def forward(self, images):\n        features = self.model(images)\n        pooled_features = self.pooling(features).flatten(1)\n        output = self.linear(pooled_features)\n        return output\n\n    \nmodel = ISICModel(CONFIG['model_name'])\nmodel.to(CONFIG['device']);","metadata":{"papermill":{"duration":1.183958,"end_time":"2024-06-29T23:18:00.375162","exception":false,"start_time":"2024-06-29T23:17:59.191204","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduction = reduction\n    def forward(self, inputs, targets):\n        BCE_loss = nn.functional.cross_entropy(inputs, targets)\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n        if self.reduction == 'mean':\n            return F_loss.mean()\n        elif self.reduction == 'sum':\n            return F_loss.sum()\n        else:\n            return F_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# criterion=FocalLoss()\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pauc_metric(y_true, y_scores, tpr_threshold=0.8):\n\n    # Calculate ROC curve\n    fpr, tpr, thresholds = roc_curve(y_true.cpu().detach(), y_scores.cpu().detach())\n\n    # Create a mask for TPR values above the threshold\n    mask = tpr >= tpr_threshold\n\n    \n    # Filter FPR and TPR values based on the mask\n    fpr_above_threshold = fpr[mask]\n    tpr_above_threshold = tpr[mask]\n\n    # Calculate the partial AUC\n    try:\n        partial_auc = auc(fpr_above_threshold, tpr_above_threshold)\n    except:\n        return 0\n\n    # Normalize the partial AUC\n    pauc = partial_auc * (1 - tpr_threshold)\n\n    return pauc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_auroc  = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    y_true = []\n    y_pred = []\n    for step, data in bar:\n        images = data['image'].to(device, dtype=torch.float)\n        targets = data['target'].to(device, dtype=torch.float)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images).squeeze()\n        loss = criterion(outputs, targets)\n        y_pred.append(outputs)\n        y_true.append(targets)\n#         loss = loss / CONFIG['n_accumulate']\n        loss.backward()\n#         if (step + 1) % CONFIG['n_accumulate'] == 0:\n        optimizer.step()\n            # zero the parameter gradients\n        optimizer.zero_grad()\n        if scheduler is not None:\n            scheduler.step()\n                \n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        epoch_auroc = running_auroc / dataset_size\n        \n        del images\n        del targets\n        del batch_size\n    y_pred = torch.cat(y_pred, dim = 0)\n    y_true = torch.cat(y_true, dim = 0)\n    epoch_auroc = binary_auroc(input=torch.nn.functional.sigmoid(y_pred), target=y_true).item()\n    pauc = pauc_metric(y_true, torch.nn.functional.sigmoid(y_pred))\n    print(f'Epoch = {epoch}, Train_Loss = {epoch_loss}, Train_Auroc = {epoch_auroc}, Train_pauc = {pauc}, LR = {optimizer.param_groups[0][\"lr\"]}') \n\n    gc.collect()\n    torch.cuda.empty_cache()\n    return epoch_loss, epoch_auroc","metadata":{"papermill":{"duration":0.024329,"end_time":"2024-06-29T23:18:00.493233","exception":false,"start_time":"2024-06-29T23:18:00.468904","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"connect_y=[]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_auroc = 0.0\n    with torch.inference_mode():\n        y_pred = []\n        y_true = []\n        bar = tqdm(enumerate(dataloader), total=len(dataloader))\n        for step, data in bar:        \n            images = data['image'].to(device, dtype=torch.float)\n            targets = data['target'].to(device, dtype=torch.float)\n\n            batch_size = images.size(0)\n            outputs = model(images).squeeze()\n            y_pred.append(outputs)\n            y_true.append(targets)\n#             connect_y.append(outputs.ravel())\n            loss = criterion(outputs, targets)\n\n            running_loss += (loss.item() * batch_size)\n            dataset_size += batch_size\n\n            epoch_loss = running_loss / dataset_size\n            epoch_auroc = running_auroc / dataset_size\n        \n            del images\n            del targets\n            del batch_size\n        y_pred = torch.cat(y_pred, dim = 0)\n        y_true = torch.cat(y_true, dim = 0)\n        epoch_auroc = binary_auroc(input=torch.nn.functional.sigmoid(y_pred), target=y_true).item()\n        pauc = pauc_metric(y_true, torch.nn.functional.sigmoid(y_pred))\n        print(f'Epoch = {epoch}, Valid_Loss = {epoch_loss}, Valid_Auroc = {epoch_auroc}, Valid_pauc = {pauc}, LR = {optimizer.param_groups[0][\"lr\"]}') \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return epoch_loss, epoch_auroc","metadata":{"papermill":{"duration":0.02315,"end_time":"2024-06-29T23:18:00.551972","exception":false,"start_time":"2024-06-29T23:18:00.528822","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_auroc = -np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, scheduler, \n                                           dataloader=train_loader, \n                                           device=CONFIG['device'], epoch=epoch)\n        \n        val_epoch_loss, val_epoch_auroc = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n                                         epoch=epoch)\n        torch.cuda.empty_cache()\n    \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Train AUROC'].append(train_epoch_auroc)\n        history['Valid AUROC'].append(val_epoch_auroc)\n        history['lr'].append( scheduler.get_lr()[0] )\n        \n        # deep copy the model\n        if best_epoch_auroc <= val_epoch_auroc:\n            print(f\"{b_}Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n            best_epoch_auroc = val_epoch_auroc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"AUROC{:.4f}_Loss{:.4f}_epoch{:.0f}.pkl\".format(val_epoch_auroc, val_epoch_loss, epoch)\n            with open(PATH, 'wb') as f:\n                pickle.dump(model, f)\n            # Save a model file from the current directory\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best AUROC: {:.4f}\".format(best_epoch_auroc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"papermill":{"duration":0.026227,"end_time":"2024-06-29T23:18:00.614057","exception":false,"start_time":"2024-06-29T23:18:00.58783","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n#     scheduler = scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n        \n    return scheduler","metadata":{"papermill":{"duration":0.020426,"end_time":"2024-06-29T23:18:00.646386","exception":false,"start_time":"2024-06-29T23:18:00.62596","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_loaders(df, fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    print(df_train.shape)\n    \n    train_dataset = ISICDataset_for_Train(df_train, transforms=data_transforms[\"train\"])\n    valid_dataset = ISICDataset(df_valid, transforms=data_transforms[\"valid\"])\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=4, shuffle=True, pin_memory=True, drop_last=False)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=4, shuffle=False, pin_memory=True)\n    print(train_dataset.__len__())\n    print(len(train_loader))\n    \n    return train_loader, valid_loader","metadata":{"papermill":{"duration":0.02047,"end_time":"2024-06-29T23:18:00.678761","exception":false,"start_time":"2024-06-29T23:18:00.658291","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 1.5em; font-weight: 300;\">Prepare Dataloaders</span>","metadata":{"papermill":{"duration":0.011803,"end_time":"2024-06-29T23:18:00.702461","exception":false,"start_time":"2024-06-29T23:18:00.690658","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_loader, valid_loader = prepare_loaders(df, fold=0)","metadata":{"papermill":{"duration":0.033503,"end_time":"2024-06-29T23:18:00.747996","exception":false,"start_time":"2024-06-29T23:18:00.714493","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_t = df[df.kfold != 0].reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_valid = df[df.kfold == 0].reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n                       weight_decay=CONFIG['weight_decay'])\nscheduler = fetch_scheduler(optimizer)","metadata":{"papermill":{"duration":0.021007,"end_time":"2024-06-29T23:18:00.805494","exception":false,"start_time":"2024-06-29T23:18:00.784487","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, history = run_training(model, optimizer, scheduler,\n                              device=CONFIG['device'],\n                              num_epochs=100)","metadata":{"papermill":{"duration":745.635338,"end_time":"2024-06-29T23:30:26.519348","exception":false,"start_time":"2024-06-29T23:18:00.88401","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"connect_dataset = ISICDataset(df, transforms=data_transforms[\"valid\"])\nconnect_loader = DataLoader(connect_dataset, batch_size=16, \n                              num_workers=4, shuffle=False, pin_memory=True)\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"connect_y=[]\nmodel=model.to(CONFIG['device'])\nwith torch.inference_mode():\n    bar = tqdm(enumerate(connect_loader), total=len(connect_loader))\n    for step, data in bar:\n        torch.cuda.empty_cache()\n        images = data['image'].to(CONFIG['device'], dtype=torch.float)\n        targets = data['target'].to(CONFIG['device'], dtype=torch.float)\n        connect_y.append(model(images))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = torch.cat(connect_y, dim = 0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred=y_pred.squeeze()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred=np.asarray(y_pred.cpu())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = pd.DataFrame.from_dict(history)\nhistory.to_csv(\"history.csv\", index=False)","metadata":{"papermill":{"duration":0.408452,"end_time":"2024-06-29T23:30:27.325321","exception":false,"start_time":"2024-06-29T23:30:26.916869","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"Train Loss\"].values, label=\"Train Loss\")\nplt.plot( range(history.shape[0]), history[\"Valid Loss\"].values, label=\"Valid Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.673512,"end_time":"2024-06-29T23:30:29.236485","exception":false,"start_time":"2024-06-29T23:30:28.562973","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"Train AUROC\"].values, label=\"Train AUROC\")\nplt.plot( range(history.shape[0]), history[\"Valid AUROC\"].values, label=\"Valid AUROC\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"AUROC\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.648584,"end_time":"2024-06-29T23:30:30.277915","exception":false,"start_time":"2024-06-29T23:30:29.629331","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"lr\"].values, label=\"lr\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"lr\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.617692,"end_time":"2024-06-29T23:30:31.290602","exception":false,"start_time":"2024-06-29T23:30:30.67291","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nfile_path = '/kaggle/working/eff_net_2_model.pkl'\nwith open(file_path, 'wb') as f:\n    pickle.dump(model, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_unique_train=['lesion_id', 'iddx_full', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4', 'iddx_5', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_lv_dnn_lesion_confidence']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = pd.read_csv('/kaggle/input/oof-predsb3/v5oof_predictions.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = y_pred.set_index('isic_id')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f['connect_y']=y_pred['oof_prediction']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df=df.drop(cols_unique_train,axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nimport optuna","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\n\nimport h5py\nfrom PIL import Image\nfrom io import BytesIO\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'target'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42\n\nnum_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n]\n\nnew_num_cols = [\n    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n\n    'position_distance_3d',          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n\n    'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n    'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n    'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n    'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'shape_complexity_index',        # border_complexity       + lesion_shape_index\n    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n\n    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'lesion_orientation_3d',         # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n\n    'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n    'border_color_interaction_2',\n    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'age_normalized_nevi_confidence',# tbp_lv_nevi_confidence  / age_approx\n    'age_normalized_nevi_confidence_2',\n    'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n\n    'volume_approximation_3d',       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution', 'combined_anatomical_site']\nnorm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\nspecial_cols = ['count_per_patient']\nfeature_cols = num_cols + new_num_cols + cat_cols + norm_cols + special_cols + ['connect_y']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pre_preprocess(df_train, df_test):\n    global cat_cols\n    \n    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n    encoder.fit(df_train[cat_cols])\n    \n    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n\n    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n\n    for col in cat_cols:\n        feature_cols.remove(col)\n\n    feature_cols.extend(new_cat_cols)\n    cat_cols = new_cat_cols\n    \n    return df_train, df_test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.set_index('isic_id', drop = False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df2 = pl.from_pandas(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.read_csv(path)\n        .with_columns(\n            pl.col('age_approx').cast(pl.String).replace('NA', np.nan).cast(pl.Float64),\n        )\n        .with_columns(\n            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n        )\n        .with_columns(\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n        )\n        .with_columns(\n            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n        )\n        .with_columns(\n            pl.col(cat_cols).cast(pl.Categorical),\n        )\n        .to_pandas()\n        .set_index(id_col)\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = read_data(train_path)\ndf_test = read_data(test_path)\n# df_subm = pd.read_csv(subm_path, index_col=id_col)\n\ndf_train2, df_test2 = pre_preprocess(df_train, df_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = df_train2.loc[df.index]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train['kfold'] = df['kfold']\ndf_train['connect_y'] = y_pred.loc[df_train.index, 'oof_prediction']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols+=['target']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[cols for cols in df_f.columns ]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[cols for cols in df_f.columns if cols not in feature_cols]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"obj_but_not_cat=['image_type','copyright_license','attribution','patient_id']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess(df,cat_labels):\n#     t=pd.read_csv('/kaggle/input/isic-2024-challenge/train-metadata.csv')\n#     for col in t.columns:\n#         if((t[col].dtype=='float64' or t[col].dtype=='int64') and t[col].isna().sum()!=0):\n#             t[col].fillna(value=t[col].median(),inplace=True);\n#         if(t[col].dtype=='object' and t[col].isna().sum()!=0):\n#             t[col].fillna(value=t[col].mode()[0],inplace=True);\n    for col in df.columns:\n        if((df[col].dtype=='float64' or df[col].dtype=='int64') and df[col].isna().sum()!=0):\n            df[col].fillna(value=df[col].mean(),inplace=True);\n        if(df[col].dtype=='object' and df[col].isna().sum()!=0):\n            df[col].fillna(value=df[col].mode()[0],inplace=True);\n#     encoder = OneHotEncoder(sparse_output=False, drop='first')\n#     encoder.fit(t[cat_labels])\n#     one_hot_encoded = encoder.transform(df[cat_labels])\n#     one_hot_df = pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(cat_labels))\n#     df_encoded = pd.concat([df.drop(columns=cat_labels), one_hot_df], axis=1)\n    target=df['target']\n    df_f=df.drop(obj_but_not_cat,axis=1)\n    df_f['target']=target\n    return df_f","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"not_scale = cat_cols + ['kfold', 'target'] ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# to_be_scaled = [cols for cols in df_f.columns if cols not in not_scale]\nto_be_scaled = num_cols + new_num_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f=preprocess(df_train,cat_cols)\n# df_f=df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = df_f['target']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CONFIG['device']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf_f[to_be_scaled] = scaler.fit_transform(df_f[to_be_scaled], y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TabularDataset(Dataset):\n    def __init__(self, data, target_column, transform=None):\n        self.data = data.drop(columns=[target_column])\n        self.targets = data[target_column]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        X = self.data.iloc[idx].values.astype(float)\n        y = self.targets.iloc[idx].astype(float)\n        \n        if self.transform:\n            X = self.transform(X)\n            \n        return {'meta':torch.tensor(X, dtype=torch.float32),\n                'target':torch.tensor(y, dtype=torch.float32)}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f['kfold'] = df['kfold']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_f=df_f.drop(['patient_id','file_path','isic_id'],axis =1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MetaModel(nn.Module):\n    def __init__(self,in_features):\n        super().__init__()\n        self.model=nn.Sequential(\n                    nn.Linear(in_features,512),\n                    nn.BatchNorm1d(512),\n                    nn.ReLU(),\n                    nn.Dropout(p=0.7),\n                    nn.Linear(512,128),\n                    nn.BatchNorm1d(128),\n                    nn.ReLU(),\n                    nn.Dropout(p=0.7),\n                    nn.Linear(128,1))\n    def forward(self,x):\n        return self.model(x)\nmeta_model=MetaModel(222)\nmeta_model=meta_model.to(CONFIG['device'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_loaders(df, fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_dataset = TabularDataset(df_train.drop(['kfold'],axis=1),'target')\n    valid_dataset = TabularDataset(df_valid.drop(['kfold'],axis=1),'target')\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=4, shuffle=True, pin_memory=False, drop_last=False)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=4, shuffle=False, pin_memory=False)\n    \n    return train_loader, valid_loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_one_epoch_meta(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_auroc  = 0.0\n    y_pred=[]\n    y_true=[]\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        meta = data['meta'].to(device, dtype=torch.float)\n        targets = data['target'].to(device, dtype=torch.float)\n        \n        batch_size = meta.size(0)\n        \n        outputs = model(meta).squeeze()\n        loss = criterion(outputs, targets)\n        y_pred.append(outputs)\n        y_true.append(targets)\n#         loss = loss / CONFIG['n_accumulate']\n        loss.backward()\n#         if (step + 1) % CONFIG['n_accumulate'] == 0:\n        optimizer.step()\n            # zero the parameter gradients\n        optimizer.zero_grad()\n        if scheduler is not None:\n            scheduler.step()\n                \n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        epoch_auroc = running_auroc / dataset_size\n        \n    y_pred = torch.cat(y_pred, dim = 0)\n    y_true = torch.cat(y_true, dim = 0)\n    epoch_auroc = binary_auroc(input=torch.nn.functional.sigmoid(y_pred), target=y_true).item()\n    pauc = pauc_metric(y_true, torch.nn.functional.sigmoid(y_pred))\n    print(f'Epoch = {epoch}, Train_Loss = {epoch_loss}, Train_Auroc = {epoch_auroc}, Train_pauc = {pauc}, LR = {optimizer.param_groups[0][\"lr\"]}') \n\n    \n    return epoch_loss, epoch_auroc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.inference_mode()\ndef valid_one_epoch_meta(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    running_auroc = 0.0\n    y_pred = [] \n    y_true = []\n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        meta = data['meta'].to(device, dtype=torch.float)\n        targets = data['target'].to(device, dtype=torch.float)\n        \n        batch_size = meta.size(0)\n\n        outputs = model(meta).squeeze()\n        y_pred.append(outputs)\n        y_true.append(targets)\n#             connect_y.append(outputs.ravel())\n        loss = criterion(outputs, targets)\n\n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n\n        epoch_loss = running_loss / dataset_size\n        epoch_auroc = running_auroc / dataset_size\n\n    y_pred = torch.cat(y_pred, dim = 0)\n    y_true = torch.cat(y_true, dim = 0)\n    epoch_auroc = binary_auroc(input=torch.nn.functional.sigmoid(y_pred), target=y_true).item()\n    pauc = pauc_metric(y_true, torch.nn.functional.sigmoid(y_pred))\n    print(f'Epoch = {epoch}, Valid_Loss = {epoch_loss}, Valid_Auroc = {epoch_auroc}, Valid_pauc = {pauc}, LR = {optimizer.param_groups[0][\"lr\"]}') \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return epoch_loss, pauc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, train_loader_meta, valid_loader_meta,device, num_epochs):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_auroc = -np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss, train_epoch_auroc = train_one_epoch_meta(model, optimizer, scheduler, \n                                           dataloader=train_loader_meta, \n                                           device=CONFIG['device'], epoch=epoch)\n        \n        val_epoch_loss, val_epoch_auroc = valid_one_epoch_meta(model, valid_loader_meta, device=CONFIG['device'], \n                                         epoch=epoch)\n    \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Train AUROC'].append(train_epoch_auroc)\n        history['Valid AUROC'].append(val_epoch_auroc)\n        history['lr'].append( scheduler.get_lr()[0] )\n        \n        # deep copy the model\n        if best_epoch_auroc <= val_epoch_auroc:\n            print(f\"{b_}Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n            best_epoch_auroc = val_epoch_auroc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"AUROC{:.4f}_Loss{:.4f}_epoch{:.0f}.bin\".format(val_epoch_auroc, val_epoch_loss, epoch)\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best AUROC: {:.4f}\".format(best_epoch_auroc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer2 = optim.Adam(meta_model.parameters(), lr=CONFIG['learning_rate'], \n                       weight_decay=CONFIG['weight_decay'])\nscheduler2 = fetch_scheduler(optimizer2, )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CONFIG['device']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols+=['kfold']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'kfold' in feature_cols","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f2 = df_f.reset_index(drop = True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f2.loc[:, 'kfold'] = df['kfold'].reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f2.loc[:, 'connect_y'] = y_pred['oof_prediction'].reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del df_f['kfold']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_f['connect_y']=y_pred['oof_prediction']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['kfold']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[cols for cols in df_f.columns if df_f[cols].isna().sum()>0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for f in range(CONFIG['n_fold']):\n    print('-------------------------------Fold ',{f},'-------------------------------------------------')\n    train_loader_meta, valid_loader_meta = prepare_loaders(df_f[feature_cols], fold=CONFIG[\"fold\"])\n    meta_model, history2 = run_training(meta_model, optimizer, scheduler,train_loader_meta,\n                              valid_loader_meta,\n                              device=CONFIG['device'],\n                              num_epochs=8)\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nfile_path = '/kaggle/working/meta_model_8_model.pkl'\nwith open(file_path, 'wb') as f:\n    pickle.dump(meta_model, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train=df_f","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n    v_gt = abs(np.asarray(solution.values)-1)\n    v_pred = np.array([1.0 - x for x in submission.values])\n    max_fpr = abs(1-min_tpr)\n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    return partial_auc\n\ndef custom_lgbm_metric(y_true, y_hat):\n    # TODO: Refactor with the above.\n    min_tpr = 0.80\n    v_gt = abs(y_true-1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    max_fpr = abs(1-min_tpr)\n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    return \"pauc80\", partial_auc, True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meta_model.state_dict = torch.load( '/kaggle/working/AUROC0.1624_Loss0.0209_epoch3.bin')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\npickle.dump(meta_model, open('nn1.162.pkl', 'wb'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N_SPLITS=5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.columns = df_train.columns.str.replace(r'[^\\w\\s]', '_', regex=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_cols=df_train.drop(['kfold','target'],axis=1).columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial):\n    param = {\n        \"objective\":         \"binary\",\n        # \"metric\":           \"custom\",\n        \"verbosity\":         -1,\n        \"boosting_type\":     \"gbdt\",\n        \"lambda_l1\":         trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\":         trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\":        trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\":  trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\":  trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\":      trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n        \"device\":            \"gpu\"\n    }\n    \n    scores = []\n    \n    for fold in range(N_SPLITS):\n        _df_train = df_train[df_train[\"kfold\"] != fold].reset_index(drop=True)\n        _df_valid = df_train[df_train[\"kfold\"] == fold].reset_index(drop=True)\n        dtrain = lgb.Dataset(_df_train[train_cols], label=_df_train[\"target\"])\n        gbm = lgb.train(param, dtrain)\n        preds = gbm.predict(_df_valid[train_cols])\n        score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n        scores.append(score)\n        \n    return np.mean(scores)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OPTIMIZE_OPTUNA= False","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if OPTIMIZE_OPTUNA:\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=21)\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: {}\".format(trial.value))\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n    v_gt = abs(np.asarray(solution.values)-1)\n    v_pred = np.array([1.0 - x for x in submission.values])\n    max_fpr = abs(1-min_tpr)\n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    return partial_auc\n\ndef custom_lgbm_metric(y_true, y_hat):\n    # TODO: Refactor with the above.\n    min_tpr = 0.80\n    v_gt = abs(y_true-1)\n    v_pred = np.array([1.0 - x for x in y_hat])\n    max_fpr = abs(1-min_tpr)\n    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n    return \"pauc80\", partial_auc, True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_params_original = {\n    \"objective\": \"binary\",\n    \"verbosity\": -1,\n    \"boosting_type\": \"gbdt\",\n    \"n_estimators\": 200,\n    'learning_rate': 0.05,    \n    'lambda_l1': 4.463745456817233e-06,\n    'lambda_l2': 7.824473303015684,\n    'num_leaves': 71,\n    'feature_fraction': 0.595173790329758,\n    'bagging_fraction': 0.9255422935941319,\n    'bagging_freq': 2,\n    'min_child_samples': 6,\n    \"device\": \"gpu\"\n}\nlgb_scores = []\nlgb_models = []\noof_df = pd.DataFrame()\nfor fold in range(5):\n    _df_train = df_train[df_train[\"kfold\"] != fold].reset_index(drop=True)\n    _df_valid = df_train[df_train[\"kfold\"] == fold].reset_index(drop=True)\n    # model = lgb.LGBMClassifier(**new_params)\n    model = VotingClassifier([(f\"lgb_{i}\", lgb.LGBMClassifier(random_state=i, **new_params_original)) for i in range(7)], voting=\"soft\")\n    model.fit(_df_train[train_cols], _df_train[\"target\"])\n    preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n    score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(preds, columns=[\"prediction\"]), \"\")\n    print(f\"fold: {fold} - Partial AUC Score: {score:.5f}\")\n    lgb_models.append(model)\n    oof_single = _df_valid[[ \"target\"]].copy()\n    oof_single[\"pred\"] = preds\n    oof_df = pd.concat([oof_df, oof_single])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgbm_score = comp_score(oof_df[\"target\"], oof_df[\"pred\"], \"\")\nprint(f\"LGBM Score: {lgbm_score:.5f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pickle\nfile_path = '/kaggle/working/lgbm_11.pkl'\nwith open(file_path, 'wb') as f:\n    pickle.dump(lgb_models, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}